# GridSearch Skyband: Otimiza√ß√£o de Hiperpar√¢metros para Modelos de Linguagem

![Python](https://img.shields.io/badge/python-3.11-blue?logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-%E2%89%A52.9.0-EE4C2C?logo=pytorch&logoColor=white)
![Transformers](https://img.shields.io/badge/transformers-%E2%89%A55.2.0-FFD21E?logo=huggingface&logoColor=black)
![codecarbon](https://img.shields.io/badge/codecarbon-%E2%89%A53.2.2-4CAF50?logo=leaflet&logoColor=white)
![Tests](https://img.shields.io/badge/tests-128%20passing-brightgreen?logo=pytest&logoColor=white)

Para executar no **Google Colab**, acesse:

- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ptcAKCC_f7lX5y9B_zJ3iisO11W1Ny2K)

## Instala√ß√£o

O projeto usa [`uv`](https://docs.astral.sh/uv/) como gerenciador de ambiente e depend√™ncias. O `requirements.txt` presente no reposit√≥rio √© gerado automaticamente ‚Äî **n√£o o edite diretamente**; a fonte de verdade √© o `pyproject.toml`.

### Pr√©-requisitos

- Python ‚â• 3.11
- [`uv`](https://docs.astral.sh/uv/getting-started/installation/) instalado
- (Opcional) NVIDIA GPU com CUDA 12.8 para acelera√ß√£o

### Passos

```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/gassantos/gridsearch-skyband.git
cd gridsearch-skyband

# 2. Crie o ambiente virtual e instale as depend√™ncias de produ√ß√£o
uv sync

# 3. (Opcional) Instale tamb√©m as depend√™ncias de desenvolvimento (pytest, etc.)
uv sync --group dev
```

> **Plataforma Linux (CUDA 12.8):** o `pyproject.toml` j√° configura automaticamente o √≠ndice `pytorch-cu128`. Em macOS/Windows, o √≠ndice `pytorch-cpu` √© selecionado sem necessidade de configura√ß√£o adicional.

### Verificar instala√ß√£o

```bash
uv run python -c "import torch; print(torch.__version__, '| CUDA:', torch.cuda.is_available())"
```

---

## Testes

A suite de testes cobre os componentes cr√≠ticos do pipeline de treinamento (101 testes pytest).

```bash
# Suite completa
uv run --group dev pytest

# Com relat√≥rio de cobertura por m√≥dulo
uv run --group dev pytest --cov=. --cov-report=term-missing

# Arquivo espec√≠fico
uv run --group dev pytest tests/test_optimizer.py -v

# Classe espec√≠fica
uv run --group dev pytest tests/test_warmup_scheduler.py::TestSchedulerLRBehavior -v
```

| Arquivo de teste | Cobertura |
|---|---|
| `test_optimizer.py` | Tipos e hiperpar√¢metros de todos os otimizadores (Adam, AdamW, SGD, bert_adam) |
| `test_warmup_scheduler.py` | C√°lculo de steps, comportamento de LR no warmup/decaimento, restaura√ß√£o de estado |
| `test_checkpoint.py` | Chaves obrigat√≥rias, round-trip do warmup scheduler, `trained_epoch` e `global_step` |
| `test_init_tool_state.py` | Carregamento de estado em `init_all`, toler√¢ncia a checkpoint inv√°lido |
| `test_gridsearch.py` | Gera√ß√£o de grade, valida√ß√£o de mem√≥ria, filtragem de config, an√°lise de resultados |
| `test_gridsearch_config.py` | Estrutura e naming dos arquivos JSON de configura√ß√£o do grid |

---

## Pipeline de Funcionamento

```mermaid
flowchart TB
 subgraph ORC["‚ë† Orquestra√ß√£o"]
    direction LR
        A["main.py<br>--mode single | grid"]
        B[["GridSearch Core<br>Process Pool ¬∑ spawn"]]
  end
 subgraph EXEC["‚ë° Execu√ß√£o"]
    direction LR
        D["init_all()  ‚Üí  run_train()<br>Pipeline"]
        E{{"CodeCarbon ¬∑ psutil<br>TeeStream"}}
  end
 subgraph RESULT["‚ë¢ Resultados"]
    direction LR
        G["Precision ¬∑ Recall ¬∑ F1 ¬∑ Accuracy"]
        F[/"Makespan ¬∑ CO‚ÇÇ kg ¬∑ kWh ¬∑ USD"/]
  end
    A -- "mode = grid" --> B
    A -- "mode = single" --> C(["execute_experiment()<br>Motor de Execu√ß√£o Central"])
    B --> C
    C --> D
    C -. thread daemon .-> E
    D --> G & F
    E --> F
    G --> H[("JSON por execu√ß√£o<br>CSV Hist√≥rico Acumulado")]
    F --> H

     A:::cli
     B:::gridsearch
     C:::engine
     D:::training
     E:::monitoring
     G:::evaluation
     F:::criteria
     H:::persistence
    classDef cli         fill:#1f6feb,stroke:#79c0ff,color:#fff,font-weight:bold
    classDef gridsearch  fill:#6e40c9,stroke:#a371f7,color:#fff,font-weight:bold
    classDef engine      fill:#e36209,stroke:#f0883e,color:#fff,font-weight:bold
    classDef training    fill:#2ea043,stroke:#56d364,color:#fff,font-weight:bold
    classDef monitoring  fill:#9a6700,stroke:#d29922,color:#fff,font-weight:bold
    classDef criteria    fill:#8250df,stroke:#bc8cff,color:#fff,font-weight:bold
    classDef evaluation  fill:#b91c1c,stroke:#f87171,color:#fff,font-weight:bold
    classDef persistence fill:#0f766e,stroke:#2dd4bf,color:#fff,font-weight:bold
```

---

## Executando Experimentos Rastre√°veis

Para pesquisa e reprodutibilidade, use `main.py` como ponto de entrada √∫nico. Ele orquestra tanto experimentos individuais quanto busca em grade de hiperpar√¢metros, delegando a execu√ß√£o ao motor `run_experiment.py`.

### Arquitetura de execu√ß√£o

```
main.py  ‚îÄ‚îÄ(mode=single)‚îÄ‚îÄ‚Üí  run_experiment.py  ‚Üí  tools/train_tool.py
         ‚îÄ‚îÄ(mode=grid)‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  gridsearch/core.py  ‚Üí  run_experiment.py
```

### Experimento √∫nico

```bash
# Execu√ß√£o padr√£o (usa config/experiments/BertPLI.config)
uv run python -m main --mode single

# Com configura√ß√£o espec√≠fica
uv run python -m main --mode single --config config/experiments/BertPLI2.config

# Diretamente pelo motor (com sele√ß√£o de GPU)
uv run python run_experiment.py config/experiments/BertPLI.config        # GPU auto
uv run python run_experiment.py config/experiments/BertPLI.config 0      # GPU 0
uv run python run_experiment.py config/experiments/BertPLI.config 0 1    # GPU 0+1
```

### Grid search de hiperpar√¢metros

```bash
# Busca minimal (teste r√°pido ‚Äî 8 combina√ß√µes, 2 workers)
uv run python -m main --mode grid \
    --grid-config gridsearch/config/grid_search_test.json \
    --parallel 2

# Busca completa (produ√ß√£o ‚Äî 216 combina√ß√µes)
uv run python -m main --mode grid \
    --grid-config gridsearch/config/grid_search.json \
    --parallel 4

# Retomar execu√ß√£o interrompida
uv run python -m main --mode grid --resume
```

> **Distribui√ß√£o de GPUs:** em modo paralelo, o `main.py` distribui os workers em round-robin pelas GPUs dispon√≠veis de forma autom√°tica. Para controle expl√≠cito, use `run_experiment.py` diretamente.

### Artefatos gerados

Cada experimento produz automaticamente em `output/experiments/metrics/`:

| Artefato | Descri√ß√£o |
|---|---|
| `<nome>_<optimizer>_<lr>_<bs>_<ep>_<timestamp>.json` | M√©tricas completas do experimento em JSON |
| `experiment_summary_<YYYYMMDD>.csv` | Agrega√ß√£o di√°ria de todos os experimentos |
| `EmissionsCO2_<device>_<YYYYMMDD>.csv` | Emiss√µes de CO‚ÇÇ rastreadas pelo `codecarbon` |

O JSON por experimento cont√©m as se√ß√µes:

```json
{
  "experiment":      { "id", "config_name", "seed", "status", "timestamp_start", "timestamp_end" },
  "environment":     { "device_type", "device_name", "precision" },
  "hyperparameters": { "optimizer", "learning_rate", "batch_size", "epoch", "avg_gflops_per_batch" },
  "resources":       { "train_time_sec", "energy_kwh", "emissions_kg_co2", "avg_ram_mb", "peak_ram_mb", "total_gflops" },
  "evaluation":      { "precision", "recall", "f1_score", "source" },
  "logs":            { "stdout_tail", "stderr_tail" }
}
```

### Ativando avalia√ß√£o autom√°tica ao final do treino

No arquivo `.config` do experimento, inclua a se√ß√£o:

```ini
[eval]
run_test_at_end = true

[data]
test_labels_file = data/task1_test_labels_2024.json
```

### Rastreamento de Emiss√µes de CO‚ÇÇ

O projeto integra o [`codecarbon`](https://mlco2.github.io/codecarbon/) para medir consumo
energ√©tico e emiss√µes de CO‚ÇÇ a cada experimento executado.

**Ativar no arquivo `.config` do experimento:**

```ini
[monitoring]
enable_monitoring = true
```

Quando ativado, ao t√©rmino do experimento:

| Sa√≠da | Descri√ß√£o |
|-------|-----------|
| Campo `energy_kwh` no JSON | Energia consumida em kWh |
| Campo `emissions_kg_co2` no JSON | Emiss√µes estimadas em kg CO‚ÇÇ |
| `output/experiments/metrics/EmissionsCO2_<device>_<YYYYMMDD>.csv` | Hist√≥rico acumulado de emiss√µes |

**Custo estimado de energia**

O custo monet√°rio √© calculado com a tarifa padr√£o de **$0,12 USD/kWh**, configur√°vel via vari√°vel de ambiente:

```bash
ENERGY_COST_USD_PER_KWH=0.08 uv run python run_experiment.py config/experiments/BertPLI.config
```

> A vari√°vel `ENERGY_COST_USD_PER_KWH` aceita qualquer valor em ponto flutuante (USD por kWh).
> O resultado aparece no campo `energy_cost_usd` do JSON de m√©tricas do experimento.

---

This repository contains the code for BERT-PLI in our IJCAI-PRICAI 2020 paper: *BERT-PLI: Modeling Paragraph-Level Interactions for Legal Case Retrieval*.

---

## Busca em Grade de Hiperpar√¢metros (Grid Search)

O m√≥dulo `gridsearch/` implementa busca exaustiva de hiperpar√¢metros com execu√ß√£o paralela, rastreamento de recursos e an√°lise autom√°tica dos resultados.

### Modos de execu√ß√£o

**Via `main.py` (recomendado):**

```bash
# Grade de teste ‚Äî 8 combina√ß√µes, valida√ß√£o r√°pida do pipeline (~2-3h com 2 workers)
uv run python -m main --mode grid \
    --grid-config gridsearch/config/grid_search_test.json \
    --parallel 2

# Grade completa ‚Äî 432 combina√ß√µes (~72-108h com 2 workers)
uv run python -m main --mode grid \
    --grid-config gridsearch/config/grid_search.json \
    --parallel 4

# Retomar execu√ß√£o interrompida (checkpoint autom√°tico por experimento)
uv run python -m main --mode grid --resume
```

**Via m√≥dulo `gridsearch` (uso program√°tico):**

```python
from gridsearch import run_grid_search, analyze_results
import json

with open("gridsearch/config/grid_search_test.json") as f:
    grid_config = json.load(f)

results = run_grid_search(
    base_config_path="config/experiments/BertPLI.config",
    grid_config=grid_config["hyperparameters"],
    parallel=2,
    gpu_ids=[0, 1],   # distribui√ß√£o round-robin por worker
)

analysis = analyze_results(results)
```

### Espa√ßo de busca

| Hiperpar√¢metro | Valores (grade completa) |
|---|---|
| `learning_rate` | `1e-5`, `2e-5`, `3e-5`, `5e-5` |
| `batch_size` | `8`, `16`, `32` |
| `optimizer` | `adam`, `adamw`, `sgd`, `bert_adam` |
| `dropout` | `0.1`, `0.2`, `0.3` |
| `seed` | `42`, `123`, `456` |
| **Total** | **432 combina√ß√µes** |

### Artefatos gerados

```
output/experiments/grid_search/
‚îú‚îÄ‚îÄ grid_search_results_<data>.json    # Resultados de todos os experimentos
‚îú‚îÄ‚îÄ grid_search_summary_<data>.txt     # Ranking leg√≠vel das melhores configura√ß√µes
‚îî‚îÄ‚îÄ grid_search_state_<data>.json      # Estado para retomada (--resume)
```

O m√≥dulo analisa e ranqueia as configura√ß√µes por 5 crit√©rios:
tempo de treinamento, consumo de energia (kWh), emiss√µes de CO‚ÇÇ (kg),
uso de RAM (MB) e F1-score de valida√ß√£o.

> Para documenta√ß√£o completa do m√≥dulo, consulte [`gridsearch/README.md`](gridsearch/README.md).

---

## Estrutura do Projeto

```
üìÅ ExperimentoBERT-PLI/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ main.py                 Orquestrador do experimento
‚îú‚îÄ‚îÄ üìÑ run_experiment.py       Motor de execu√ß√£o
‚îú‚îÄ‚îÄ üìÑ pyproject.toml          Depend√™ncias e entrypoints
‚îú‚îÄ‚îÄ üìÑ compose.yaml            Ambiente containerizado
‚îú‚îÄ‚îÄ üìÑ Dockerfile              Imagem base do projeto
‚îú‚îÄ‚îÄ üìÅ config/                 Configura√ß√µes em cascata
‚îú‚îÄ‚îÄ üìÅ model/                  Modelos LM
‚îú‚îÄ‚îÄ üìÅ formatter/              Prepara√ß√£o de inputs
‚îú‚îÄ‚îÄ üìÅ dataset/                DataLoaders
‚îú‚îÄ‚îÄ üìÅ tools/                  Treino, Avalia√ß√£o e Infer√™ncia
‚îú‚îÄ‚îÄ üìÅ scripts/                Entrypoints CLI
‚îú‚îÄ‚îÄ üìÅ gridsearch/             M√≥dulo de busca em grid
‚îú‚îÄ‚îÄ üìÅ utils/                  Utilit√°rios gerais
‚îú‚îÄ‚îÄ üìÅ tests/                  Suite com 101 testes
‚îú‚îÄ‚îÄ üìÅ data/                   Dados sint√©ticos
‚îú‚îÄ‚îÄ üìÅ examples/               Exemplos de dados
‚îú‚îÄ‚îÄ üìÅ docs/                   Documenta√ß√£o t√©cnica
‚îî‚îÄ‚îÄ üìÅ devconteiner/           Dev Container (VS Code)
```

### Exemplos de formato de dados

> **Para fins acad√™micos:** Este reposit√≥rio inclui dados sint√©ticos de casos jur√≠dicos no diret√≥rio `data/`, simulando a estrutura do dataset COLIEE:
>
> - 34 pares de par√°grafos para treino (exemplos positivos e negativos balanceados)
> - 6 pares de par√°grafos para valida√ß√£o
> - 10 documentos com m√∫ltiplos par√°grafos para teste
> - Conte√∫do jur√≠dico realista cobrindo diversos temas (contratos, direito constitucional, processo civil, etc.)
>
> **Para pesquisa/produ√ß√£o:** acesse [COLIEE 2019](https://sites.ualberta.ca/~rabelo/COLIEE2019/) para solicitar o dataset original da competi√ß√£o.

- [examples/task2/data_sample.json](examples/task2/data_sample.json): input para Est√°gio 2 (fine-tuning par de par√°grafos)

```json
{ "guid": "queryID_paraID", "text_a": "<par√°grafo decis√£o>", "text_b": "<par√°grafo candidato>", "label": 0 }
```

- [examples/task1/case_para_sample.json](examples/task1/case_para_sample.json): input para Est√°gio 3 (BertPoolOutMax)

```json
{ "guid": "queryID_docID", "q_paras": ["..."], "c_paras": ["..."], "label": 0 }
```

- [examples/task1/embedding_sample.json](examples/task1/embedding_sample.json): input para Est√°gio 4 (AttenRNN)

```json
{ "guid": "queryID_docID", "res": [[...], ...], "label": 0 }
```

### Depend√™ncias

- Gerenciadas via `pyproject.toml` + `uv`. Consulte a se√ß√£o [Instala√ß√£o](#instala√ß√£o) para instru√ß√µes completas.
- Para inspecionar as vers√µes exatas resolvidas: `uv pip list`

## Reprodutibilidade

O projeto garante resultados reproduz√≠veis por meio da fun√ß√£o `set_seed` em [utils/seed.py](utils/seed.py), que cobre todas as fontes de aleatoriedade:

| Camada | Mecanismo |
|--------|-----------|
| Python | `random.seed(seed)` |
| Python hash | `PYTHONHASHSEED=<seed>` |
| NumPy | `np.random.seed(seed)` |
| PyTorch CPU | `torch.manual_seed(seed)` |
| PyTorch CUDA | `torch.cuda.manual_seed_all(seed)` |
| cuDNN | `deterministic=True`, `benchmark=False` |
| Apple Silicon (MPS) | `torch.mps.manual_seed(seed)` |
| Transformers | `transformers.set_seed(seed)` |

### Configurando o seed pelo arquivo `.config`

```ini
[training]
seed = 42
```

O seed padr√£o √© `42`. Para m√°xima reprodutibilidade, use `ensure_reproducibility()`, que adicionalmente define `CUBLAS_WORKSPACE_CONFIG=:4096:8`:

```python
from utils.seed import ensure_reproducibility
ensure_reproducibility(seed=42)
```

### Trade-off: determinismo vs. performance

| Modo | `cudnn.deterministic` | `cudnn.benchmark` | Performance |
|------|----------------------|-------------------|-------------|
| `set_seed(seed, deterministic=True)` *(padr√£o)* | `True` | `False` | Reduzida |
| `set_seed(seed, deterministic=False)` | `False` | `True` | M√°xima |

> **Nota:** mesmo com `deterministic=True`, opera√ß√µes at√¥micas em GPU (ex.: `scatter_add`) podem introduzir varia√ß√£o residual em vers√µes mais antigas do CUDA. Para elimina√ß√£o total, use `ensure_reproducibility()`.

---

