############################################################
# EXPERIMENTO BERT-PLI
# Objetivo: Recuperação de Casos Jurídicos em Nível de Parágrafo
#
# Estratégia (Baseline):
# - AdamW com LR conservador (2e-5)
# - Mixed precision (FP16) para eficiência
# - Early stopping com paciência 2
# - Agregação via Attention-RNN
# - Warmup linear + scheduler para estabilidade
#
# Convenção de nome:
# bertpli_<optimizer>_lr<lr>_bs<batch>_ep<epoch>[_seedX].config
############################################################


############################
# METADADOS DO EXPERIMENTO
############################
[experiment]

# Identificador do experimento
name = bertpli1

# Descrição curta do racional experimental
description = |
    Cenário base com AdamW e LR conservador.
    Foco em estabilidade de gradiente e boa generalização
    para interações parágrafo-parágrafo.

# Seed para reprodutibilidade
seed = 42

############################
# AMBIENTE DE EXECUÇÃO
############################
[environment]

# Tipo de processador
# cpu | gpu | tpu
# device_type = gpu

# Identificação do hardware (livre, mas padronizado)
# device_name = NVIDIA A100 40GB

# Número de dispositivos usados
# num_devices = 1

# Precisão numérica
# fp32 | fp16 | bf16
precision = fp16

# Framework de execução
# framework = pytorch

# Observações relevantes
notes = |
    Estratégia baseline com AdamW (lr=2e-5, weight_decay=0.01) e warmup linear (10%).
    Early stopping monitora F1-score no conjunto de validação.
    Agregação via Attention-RNN (hidden_size=256) para capturar relações parágrafo-parágrafo.
    Gradient clipping (max_norm=1.0) para estabilidade durante fine-tuning do BERT.


############################
# DADOS
############################
[data]

# Diretório base do dataset
data_dir = data/

# Número máximo de parágrafos por documento
max_paragraphs = 64

# Tamanho máximo de tokens por parágrafo (BERT constraint)
max_seq_length = 256

# Configurações de dataset e formatter
train_dataset_type = JsonFromFiles
train_formatter_type = BertPairText
train_data_path = data
train_file_list = train_task2.json

valid_dataset_type = JsonFromFiles
valid_formatter_type = BertPairText
valid_data_path = data
valid_file_list = valid_task2.json

test_dataset_type = JsonFromFiles
test_formatter_type = BertPairText
test_data_path = data
test_file_list = test_task1.json

# Configurações de leitura de dados
recursive = False
json_format = line
load_into_mem = True

############################
# MODELO
############################
[model]

# Modelo base do HuggingFace
pretrained_model = bert-base-uncased

# Tipo de arquitetura de agregação
# (ex.: atten_rnn, lstm, gru, mean_pool)
aggregation_model = atten_rnn

# Dimensão do hidden state da RNN
hidden_size = 256

# Dropout aplicado após BERT e/ou agregação
dropout = 0.1

# Congelar ou não camadas do BERT
freeze_bert = false

# Número de camadas congeladas (se freeze_bert = true)
freeze_layers = 0

# Nome do modelo específico
model_name = BertPoint

# Caminho alternativo do BERT (compatibilidade)
bert_path = bert-base-uncased

# Dimensão de saída do modelo
output_dim = 2

# Modo de saída
output_mode = classification


############################
# TREINAMENTO
############################
[train]

# Número de épocas
epoch = 4

# Batch size efetivo
batch_size = 16

# Shuffle do dataset
shuffle = true

# Acumulação de gradiente (útil para GPU pequena)
gradient_accumulation_steps = 1

# Otimizador
# Opções típicas: adam, adamw, sgd, bert_adam
optimizer = adamw

# Learning rate
learning_rate = 2e-5

# Weight decay (especialmente relevante para AdamW)
weight_decay = 0.01

# Clipping de gradiente (estabilidade)
max_grad_norm = 1.0

# Warmup (fração do total de steps)
warmup_ratio = 0.1

# Scheduler
# linear, cosine, constant
lr_scheduler = linear

# Early stopping
early_stopping = true
early_stopping_patience = 2

# Número de readers (paralelização)
reader_num = 0

# Step size para scheduler
step_size = 1

# Multiplicador de learning rate
lr_multiplier = 1


############################
# AVALIAÇÃO
############################
[eval]

# Métricas principais
metrics = precision, recall, f1

# Avaliar a cada N steps ou epochs
eval_strategy = epoch

# Salvar melhor modelo com base em:
monitor_metric = f1
monitor_mode = max

# Avaliar no conjunto de teste ao final?
# pool_out=True: este config é o estágio 1 do pipeline BertPLI (extrator de embeddings).
# A avaliação de recuperação é feita pelo AttenRNN (estágio 2). Manter false aqui.
run_test_at_end = false

# Batch size para avaliação
eval_batch_size = 8

# Número de readers para avaliação
eval_reader_num = 0


############################
# LOGGING & OUTPUT
############################
[logging]

# Diretório base de saída
output_dir = output/experiment

# Salvar checkpoints?
save_checkpoints = true

# Frequência de salvamento
save_strategy = epoch

# Logar curvas de loss
log_loss = true

# Logar métricas detalhadas
log_metrics = true

# Integração opcional (ex.: wandb, tensorboard)
logger = tensorboard


############################
# OUTPUT
############################
[output]

# Frequência de output durante treinamento
output_time = 1

# Frequência de teste
test_time = 1

# Caminho para salvar modelos
model_path = output/checkpoints

# Nome do modelo salvo
model_name = bert_finetuned

# Pooling output
pool_out = True

# Salvar como dicionário
save_as_dict = True

# Caminho do tensorboard
tensorboard_path = output/tensorboard

# Método de cálculo de acurácia
accuracy_method = SingleLabelTop1

# Função de output
output_function = Basic

# Valores de output
output_value = micro_precision,macro_precision,macro_recall,macro_f1

# Largura da barra de progresso TQDM
tqdm_ncols = 150

############################
# MONITORAMENTO DE RECURSOS
############################
[monitoring]

# Ativar monitoramento ambiental?
enable_monitoring = true

# Métricas a coletar
collect_energy = true        # kWh
collect_ram = true           # MB
collect_flops = true         # GFLOPs
collect_time = true          # segundos

# Ferramentas esperadas
# codecarbon, pynvml, psutil, torch.profiler
energy_tool = codecarbon
ram_tool = psutil
flops_tool = torch_profiler

# Frequência de coleta
# step | epoch
monitoring_granularity = epoch

# Diretório de saída das métricas
metrics_output_dir = outputs/metrics/

# Salvar métricas agregadas por execução
save_summary = true